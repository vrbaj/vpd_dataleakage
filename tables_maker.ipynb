{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Table maker",
   "id": "ba43c13c0baaa675"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T02:11:42.207582Z",
     "start_time": "2025-06-06T02:11:40.758411Z"
    }
   },
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results_dir = Path(\".\", \"results_minimal\")\n",
    "results_stratified_dir = Path(\".\", \"results_minimal_stratified\")\n",
    "scaling_transformations = set([str(file).split(\"_\")[2] for file in list(results_dir.glob(\"*.json\"))])\n",
    "scaling_transformations"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MaxAbsScaler',\n",
       " 'MinMaxScaler',\n",
       " 'QuantileTransformer',\n",
       " 'RobustScaler',\n",
       " 'StandardScaler'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Table with results for each scaler",
   "id": "cb348f7f019da37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T02:12:08.286072Z",
     "start_time": "2025-06-06T02:11:46.016824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through the scaler types\n",
    "for scaler in scaling_transformations:\n",
    "    # Iterate through non-stratified and stratified results\n",
    "    for split_type, split_type_name in zip([results_dir, results_stratified_dir], [\"nonstratified\", \"stratified\"]):\n",
    "        scaler_results = pd.DataFrame(data=None, columns=None, index=[\"max\", \"min\", \"mean\", \"std\"])\n",
    "        # Iterate through individual model results for the given scaler type and split type\n",
    "        for result in results_dir.glob(f\"*{scaler}*\"):\n",
    "            # Load the result\n",
    "            data = pd.read_json(result).transpose()\n",
    "            # Get the leakage and correct BCC values\n",
    "            data = pd.json_normalize(data[\"bcc\"])\n",
    "            # Calculate the difference\n",
    "            data[\"diff\"] = data[\"leakage\"] - data[\"correct\"]\n",
    "            # Get the metrics\n",
    "            col = data[[\"diff\"]].agg(func=[\"max\", \"min\", \"mean\", \"std\"])\n",
    "            # Name the column with the name of the classifier\n",
    "            col.columns = [result.stem.split(\"_\")[-1]]\n",
    "            # Concatenate the column with the performance of previous results\n",
    "            scaler_results = pd.concat([scaler_results, col], axis=1)\n",
    "        # Transpose the results so classifiers are rows\n",
    "        scaler_results = scaler_results.transpose().reset_index().rename(columns={\"index\": \"classifier\"})\n",
    "        # Once all results for the split type and scaler are added, save them\n",
    "        scaler_results.to_csv(f\"scaler_{scaler}_split_{split_type_name}.csv\", index=False)\n"
   ],
   "id": "ee55710f08b6d9c2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pandas_tables = []\n",
    "\n",
    "for scaler in scaling_transformations:\n",
    "    scaler_table = {\"classifier\": [],\n",
    "                    \"maxdiff\": [],\n",
    "                    \"mindiff\": [],\n",
    "                    \"meandiff\": [],\n",
    "                    \"stddiff\": [],\n",
    "                    \"bestdiff\": [],\n",
    "                    \"bestcorrect\": [],\n",
    "                    \"meancorrect\": [],\n",
    "                    \"worstcorrect\": []}\n",
    "    for result in results_dir.glob(f\"*{scaler}*\"):\n",
    "        with open(result, \"r\") as f:\n",
    "            clf_results = json.load(f)\n",
    "            to_pandas = {\"seed\": [], \"bcc_correct\": [], \"bcc_leakage\": []}\n",
    "            for seed_experiment in clf_results.keys():\n",
    "                to_pandas[\"seed\"].append(int(seed_experiment))\n",
    "                to_pandas[\"bcc_correct\"].append(clf_results[seed_experiment][\"bcc\"][\"correct\"])\n",
    "                to_pandas[\"bcc_leakage\"].append(clf_results[seed_experiment][\"bcc\"][\"leakage\"])\n",
    "\n",
    "            pd_data = pd.DataFrame(to_pandas)\n",
    "            scaler_table[\"classifier\"].append(str(result.stem).split(\"_\")[4])\n",
    "            diff = pd_data[\"bcc_leakage\"] - pd_data[\"bcc_correct\"]\n",
    "            # plt.figure()\n",
    "            # plt.hist(diff, bins=100)\n",
    "            # plt.title(f\"{result.stem} - {scaler}\")\n",
    "\n",
    "            scaler_table[\"maxdiff\"].append(diff.max())\n",
    "            scaler_table[\"mindiff\"].append(diff.min())\n",
    "            scaler_table[\"meandiff\"].append(diff.mean())\n",
    "            scaler_table[\"stddiff\"].append(diff.std())\n",
    "            scaler_table[\"bestdiff\"].append(pd_data[\"bcc_leakage\"].max() - pd_data[\"bcc_correct\"].max())\n",
    "            scaler_table[\"bestcorrect\"].append(pd_data[\"bcc_correct\"].max())\n",
    "            scaler_table[\"meancorrect\"].append(pd_data[\"bcc_correct\"].mean())\n",
    "            scaler_table[\"worstcorrect\"].append(pd_data[\"bcc_correct\"].min())\n",
    "\n",
    "    pd_to_dump = pd.DataFrame(scaler_table).to_csv(f\"scaler_{scaler}.csv\")\n",
    "plt.show()"
   ],
   "id": "ccbb5247b2dd8101",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ed24e3f95e5b7e42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Code for table setup\n",
    "TABLE_START = \\\n",
    "\"\"\"\n",
    "\\\\begin{table}[]\n",
    "\\t\\\\centering\n",
    "\\t\\\\begin{tabular}{lcccc}\n",
    "\"\"\"\n",
    "\n",
    "# Encoding estimator names\n",
    "estimator_names = {    \"adaboost\":\"AdaBoost\",\n",
    "    \"dt\": \"\\\\gls{DT}\",\n",
    "    \"gaussianNB\": \"Gaussian \\\\gls{NB}\",\n",
    "    \"gaussian\": \"\\\\gls{GP}\",\n",
    "    \"knn\": \"\\\\gls{KNN}\",\n",
    "    \"lda\": \"\\\\gls{LDA}\",\n",
    "    \"mlp\": \"\\\\gls{MLP}\",\n",
    "    \"qda\": \"\\\\gls{QDA}\",\n",
    "    \"rf\": \"\\\\gls{RF}\",\n",
    "    \"svm\": \"\\\\gls{SVM}\"\n",
    "    }\n",
    "\n",
    "# Encoding column names\n",
    "col_names = {\n",
    "    \"classifier\": \"Estimator\",\n",
    "    \"maxdiff\": \"MAX\",\n",
    "    \"mindiff\": \"MIN\",\n",
    "    \"meandiff\": \"$\\\\mu$\",\n",
    "    \"stddiff\": \"$\\\\sigma$\",\n",
    "}\n",
    "# Code for table end -> needs to be formatted to add the name of the tranformer\n",
    "table_end = \\\n",
    "\"\"\"\n",
    "\\t\\\\end{{tabular}}\n",
    "\\t\\\\caption{{Data leakage results for {transformer}}}\n",
    "\\t\\\\label{{tab:{transformer_label}}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "# Getting the name of the transformer\n",
    "table_latex = \"\"\n",
    "for transformer in [\"MaxAbsScaler\", \"MinMaxScaler\", \"QuantileTransformer\", \"RobustScaler\", \"StandardScaler\"]:\n",
    "    # Loading data\n",
    "    data = pd.read_csv(f\"scaler_{transformer}.csv\").iloc[:, 1:6]\n",
    "    # Adding a toprule\n",
    "    table_header = \"\\t\\t\\\\toprule\\n\"\n",
    "    # Creating a table header from the dataframe column names\n",
    "    table_header += \"\\t\\t\" + \" & \".join( [col_names[x] for x in data.columns.to_list()]) + \" \\\\\\\\\\n\"\n",
    "    # Adding a midrule\n",
    "    table_header += \"\\t\\t\\\\midrule\"\n",
    "    # Creating the table body with values for each model\n",
    "    table_body = \"\"\n",
    "    for row in data.iterrows():\n",
    "      # Saving only the values (discarding indices) as a list\n",
    "      row_as_list = row[1].to_list()\n",
    "      # Formatting the values as floats with 3 decimals\n",
    "      row_formatted = [estimator_names[row_as_list[0]]] + [f\"{val:.3f}\" for val in row_as_list[1:]]\n",
    "      # Creating a latex code for the row with values\n",
    "      if row[0] == 0:\n",
    "        table_row = \"\\n\\t\\t\" + \" & \".join(row_formatted)\n",
    "      else:\n",
    "        table_row = \" \\\\\\\\\\n\\t\\t\" + \" & \".join(row_formatted)\n",
    "      # Adding the code to the existing table body\n",
    "      table_body += table_row\n",
    "    # Adding a bottomrule\n",
    "    table_body += \"\\\\\\\\\\n\\t\\t\\\\bottomrule\"\n",
    "\n",
    "    #\n",
    "    table_latex += TABLE_START + table_header + table_body + table_end.format(transformer=transformer, transformer_label=transformer.replace(\" \",\"_\").lower())\n",
    "\n",
    "with open(\"latex_tables.tex\", \"w\") as f:\n",
    "  f.write(table_latex)"
   ],
   "id": "b85d3ccece227342",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
