{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Table maker",
   "id": "ff8b1eb83cf7499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:15:48.709219Z",
     "start_time": "2025-06-06T07:15:48.700904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "results_dir = Path(\".\", \"svd_results_minimal\")\n",
    "# results_stratified_dir = Path(\".\", \"results_minimal_stratified\")\n",
    "datasets = [\"svd\", \"voiced\"]\n",
    "scaling_transformations = set([str(file.name).split(\"_\")[1] for file in list(results_dir.glob(\"*.json\"))])\n",
    "scaling_transformations"
   ],
   "id": "f5d1d1238f37a64b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Table with results for each scaler",
   "id": "d7dd07a5b55dd33b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:15:25.521659Z",
     "start_time": "2025-06-06T07:15:25.511146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through datasets\n",
    "for dataset in datasets:\n",
    "    results_dir = Path(\".\", f\"{dataset}_results_minimal\")\n",
    "    results_stratified_dir = Path(\".\", f\"{dataset}_results_minimal_stratified\")\n",
    "    # Iterate through the scaler types\n",
    "    for scaler in scaling_transformations:\n",
    "        # Iterate through non-stratified and stratified results\n",
    "        for split_type, split_type_name in zip([results_dir, results_stratified_dir], [\"nonstratified\", \"stratified\"]):\n",
    "            scaler_results = pd.DataFrame(data=None, columns=None, index=[\"max\", \"min\", \"mean\", \"std\"])\n",
    "            # Iterate through individual model results for the given scaler type and split type\n",
    "            for result in split_type.glob(f\"*{scaler}*\"):\n",
    "                # Load the result\n",
    "                data = pd.read_json(result).transpose()\n",
    "                # Get the leakage and correct BCC values\n",
    "                data = pd.json_normalize(data[\"bcc\"])\n",
    "                # Calculate the difference\n",
    "                data[\"diff\"] = data[\"leakage\"] - data[\"correct\"]\n",
    "                # Get the metrics\n",
    "                col = data[[\"diff\"]].agg(func=[\"max\", \"min\", \"mean\", \"std\"])\n",
    "                # Name the column with the name of the classifier\n",
    "                col.columns = [result.stem.split(\"_\")[-1]]\n",
    "                # Concatenate the column with the performance of previous results\n",
    "                scaler_results = pd.concat([scaler_results, col], axis=1)\n",
    "            # Transpose the results so classifiers are rows\n",
    "            scaler_results = scaler_results.transpose().reset_index().rename(columns={\"index\": \"classifier\"})\n",
    "            # Once all results for the split type and scaler are added, save them\n",
    "            print(f\"scaler_{scaler}_split_{split_type_name}_dataset_{dataset}.csv\")\n",
    "            scaler_results.to_csv(f\"scaler_{scaler}_split_{split_type_name}_dataset_{dataset}.csv\", index=False)\n"
   ],
   "id": "4a55c9621e4083fc",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:15:25.581696Z",
     "start_time": "2025-06-06T07:15:25.562498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Code for table setup\n",
    "TABLE_START = \\\n",
    "\"\"\"\n",
    "\\\\begin{table}[t]\n",
    "\\t\\\\centering\n",
    "\\t\\\\begin{tabular}{llcccccccc}\n",
    "\\t\\t\\\\toprule\n",
    "\\t\\t & & \\\\multicolumn{4}{c}{Unstratified split} & \\\\multicolumn{4}{c}{Stratified split} \\\\\\\\\n",
    "\"\"\"\n",
    "\n",
    "# Encoding estimator names\n",
    "estimator_names = {\n",
    "    \"adaboost\":\"\\\\gls{AB}\",\n",
    "    \"dt\": \"\\\\gls{DT}\",\n",
    "    \"gaussianNB\": \"\\\\gls{GNB}\",\n",
    "    \"process\": \"\\\\gls{GP}\",\n",
    "    \"knn\": \"\\\\gls{KNN}\",\n",
    "    \"lda\": \"\\\\gls{LDA}\",\n",
    "    \"mlp\": \"\\\\gls{MLP}\",\n",
    "    \"qda\": \"\\\\gls{QDA}\",\n",
    "    \"rf\": \"\\\\gls{RF}\",\n",
    "    \"svm\": \"\\\\gls{SVM}\"\n",
    "    }\n",
    "\n",
    "# Encoding column names\n",
    "col_names = {\n",
    "    \"classifier\": \"Model\",\n",
    "    \"max\": \"Max\",\n",
    "    \"min\": \"Min\",\n",
    "    \"mean\": \"$\\\\mu$\",\n",
    "    \"std\": \"$\\\\sigma$\",\n",
    "}\n",
    "# Code for table end -> needs to be formatted to add the name of the tranformer\n",
    "table_end = \\\n",
    "\"\"\"\n",
    "\\t\\\\end{{tabular}}\n",
    "\\t\\\\caption{{Data leakage results for {transformer}}}\n",
    "\\t\\\\label{{tab:{transformer_label}}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "# Getting the name of the transformer\n",
    "table_latex = \"\"\n",
    "for transformer in scaling_transformations:\n",
    "    # Loading data\n",
    "    table_body = \"\"\n",
    "    for index, dataset in enumerate(datasets):\n",
    "        data = pd.read_csv(f\"scaler_{transformer}_split_nonstratified_dataset_{dataset}.csv\")\n",
    "        data_stratified = pd.read_csv(f\"scaler_{transformer}_split_stratified_dataset_{dataset}.csv\")\n",
    "        if index == 0:\n",
    "            # Creating a table header from the dataframe column names for the first dataset\n",
    "            table_body += \"\\t\\t & Model & \" + \" & \".join( [col_names[x] for x in data.columns.to_list()[1:]] * 2)  + \" \\\\\\\\\\n\"\n",
    "        else:\n",
    "            # For the second dataset, only line break is added\n",
    "            table_body += \" \\\\\\\\\\n\"\n",
    "        # Adding a midrule\n",
    "        table_body += \"\\t\\t\\\\midrule\\n\"\n",
    "        # Adding the dataset name -> because of formatted print, all curly brackets in the string have to be doubled\n",
    "        table_body += f\"\\t\\t\\\\multirow{{10}}{{*}}{{\\\\rotatebox[origin=c]{{90}}{{\\\\gls{{{dataset.upper()}}}}}}}\"\n",
    "        # Creating the table body with values for each model\n",
    "        for row1, row2 in zip(data.iterrows(), data_stratified.iterrows()):\n",
    "          # Saving only the values (discarding indices) as a list\n",
    "          row_as_list = row1[1].to_list() + row2[1].to_list()[1:]\n",
    "          # Formatting the values as floats with 3 decimals\n",
    "          row_formatted = [estimator_names[row_as_list[0]]] + [f\"{val:.3f}\" for val in row_as_list[1:]]\n",
    "          # Creating a latex code for the row with values\n",
    "          if row1[0] == 0:\n",
    "            table_row = \" & \" + \" & \".join(row_formatted)\n",
    "          else:\n",
    "            table_row = \" \\\\\\\\\\n\\t\\t & \" + \" & \".join(row_formatted)\n",
    "          # Adding the code to the existing table body\n",
    "          table_body += table_row\n",
    "        # Adding a bottomrule\n",
    "    table_body += \" \\\\\\\\\\n\\t\\t\\\\bottomrule\"\n",
    "\n",
    "    #\n",
    "    table_latex += TABLE_START + table_body + table_end.format(transformer=transformer, transformer_label=transformer.replace(\" \",\"_\").lower())\n",
    "\n",
    "with open(\"latex_tables.tex\", \"w\") as f:\n",
    "  f.write(table_latex)"
   ],
   "id": "91608e641826bd75",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:15:25.702403Z",
     "start_time": "2025-06-06T07:15:25.645562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "svd = pd.read_csv(\"data/flattened_features.csv\")\n",
    "voiced = pd.read_csv(\"data/voiced_features_8000_fft.csv\")"
   ],
   "id": "7897bf887669b08e",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:15:25.772548Z",
     "start_time": "2025-06-06T07:15:25.764509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "svd_cols = set(svd.columns.to_list())\n",
    "voiced_cols = set(voiced.columns.to_list())\n",
    "svd_cols - voiced_cols"
   ],
   "id": "f3e9cbb0446b3d00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spectral_contrast_7'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
